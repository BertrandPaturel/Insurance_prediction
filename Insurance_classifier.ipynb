{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance prediction : Classification\n",
    "\n",
    "In this project the goal is to classify between the two classes 0 and 1 the fatures target_flag.\n",
    "\n",
    "## Description of my approach\n",
    "\n",
    "### Load data and useful librairy\n",
    "\n",
    "Here I load all the Library I need and the training and testing set\n",
    "\n",
    "### First dummy classifier : \n",
    "\n",
    "In the first part I will encode a dummy classifier which will be for a reference/goal to at least reach. Thus I will know how good my model is and how far I ahve improved my situation starting from a very basic classifier. The dummy classifier will only predict the most common class between 0 and 1. It is also for me a way to have a first contact with the data.\n",
    "\n",
    "### Data exploration : \n",
    "\n",
    "Then I will explore the distribution of my features and my target. It is a way for me to know what king of model could be apply, what are the roles between the different features and to detect some imbalanced data.\n",
    "\n",
    "### Data treatment : \n",
    "\n",
    "I will then be able : \n",
    "- to complete the mising values if there are\n",
    "- properly encode the non numeric data to take them into account in my model.\n",
    "- rescale the data if needed, it depends on the values and in the model that I apply\n",
    "\n",
    "\n",
    "### Machine Learning Model :\n",
    "\n",
    "Then I will choose a relevant algorithm and finetuned its hyperparameters thanks to a Cross vaidation.\n",
    "\n",
    "\n",
    "### Deep Learning Model :\n",
    "\n",
    "Finally I will discuss about the different solutions in deeplearning and by the state of the art. If I have still time I will offer a way to implement one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and useful Library\n",
    "\n",
    "I need : \n",
    "\n",
    "    - panda, numpy and scickit-learn.\n",
    "    - training and testing data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the librairies I will need\n",
    "\n",
    "#Basic libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV #to make train and test data\n",
    "import csv\n",
    "\n",
    "#in order to make the pipelines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#for preprocessing the data\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer #a transformer has to be different for each type of columns\n",
    "from sklearn.compose import make_column_selector #a to select our columns by their types, names etc\n",
    "\n",
    "#This is our Dummy Classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#model predictions \n",
    "import xgboost as xgb\n",
    "\n",
    "#to measure the performance of our model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "source": [
    "Now it is time to load our training and testing set."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'auto-insurance-fall-2017/test_auto.csv' #change it if differs on your computer\n",
    "train_path = 'auto-insurance-fall-2017/train_auto.csv' #change it if differs on your computer\n",
    "target_amt_path = 'auto-insurance-fall-2017/SHELL_AUTO.csv' #change it if differs on your computer\n",
    "\n",
    "#First treatment to convert the columns with $\n",
    "false_categorical_features = {'INCOME': lambda s: s.replace('$', '').replace(',',''), 'HOME_VAL': lambda s: s.replace('$', '').replace(',',''), 'BLUEBOOK': lambda s: s.replace('$', '').replace(',',''), 'OLDCLAIM': lambda s: s.replace('$', '').replace(',','')}\n",
    "\n",
    "\n",
    "validation_set = pd.read_csv(test_path, converters=false_categorical_features) #our set to finally test our data set\n",
    "training_set = pd.read_csv(train_path, converters=false_categorical_features)#our train set to train our model\n",
    "TARGET_AMT = pd.read_csv(target_amt_path) \n",
    "validation_set['TARGET_AMT'] = TARGET_AMT['p_target'] # Complete the validation set\n",
    "\n",
    "#Now I convert the rows that were with dollars in integer\n",
    "for name in false_categorical_features:\n",
    "        validation_set[name] = pd.to_numeric(validation_set[name], errors='coerce', downcast='integer')\n",
    "        training_set[name] = pd.to_numeric(training_set[name], errors='coerce', downcast='integer')\n",
    "\n",
    "final_target = validation_set['TARGET_FLAG'] # This is the target that we want to predict (time series)\n",
    "validation_features = validation_set.iloc[:, validation_set.columns!='TARGET_FLAG']# the data set containing our features\n",
    "\n",
    "training_target = training_set['TARGET_FLAG'] # This is the target that we want to predict (time series)\n",
    "training_features = training_set.iloc[:, training_set.columns!='TARGET_FLAG']# the data set containing our features\n",
    "\n",
    "# It is time to split our data in two parts, the set to train on et the set to test our model:\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_features, training_target, test_size=0.2) # taking 80 % for the traind set and 20 % for the testing set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   INDEX  TARGET_FLAG  TARGET_AMT  KIDSDRIV   AGE  HOMEKIDS   YOJ    INCOME  \\\n",
       "0      1            0         0.0         0  60.0         0  11.0   67349.0   \n",
       "1      2            0         0.0         0  43.0         0  11.0   91449.0   \n",
       "2      4            0         0.0         0  35.0         1  10.0   16039.0   \n",
       "3      5            0         0.0         0  51.0         0  14.0       NaN   \n",
       "4      6            0         0.0         0  50.0         0   NaN  114986.0   \n",
       "\n",
       "  PARENT1  HOME_VAL  ... BLUEBOOK TIF CAR_TYPE RED_CAR  OLDCLAIM CLM_FREQ  \\\n",
       "0      No       0.0  ...    14230  11  Minivan     yes      4461        2   \n",
       "1      No  257252.0  ...    14940   1  Minivan     yes         0        0   \n",
       "2      No  124191.0  ...     4010   4    z_SUV      no     38690        2   \n",
       "3      No  306251.0  ...    15440   7  Minivan     yes         0        0   \n",
       "4      No  243925.0  ...    18000   1    z_SUV      no     19217        2   \n",
       "\n",
       "   REVOKED  MVR_PTS CAR_AGE           URBANICITY  \n",
       "0       No        3    18.0  Highly Urban/ Urban  \n",
       "1       No        0     1.0  Highly Urban/ Urban  \n",
       "2       No        3    10.0  Highly Urban/ Urban  \n",
       "3       No        0     6.0  Highly Urban/ Urban  \n",
       "4      Yes        3    17.0  Highly Urban/ Urban  \n",
       "\n",
       "[5 rows x 26 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>INDEX</th>\n      <th>TARGET_FLAG</th>\n      <th>TARGET_AMT</th>\n      <th>KIDSDRIV</th>\n      <th>AGE</th>\n      <th>HOMEKIDS</th>\n      <th>YOJ</th>\n      <th>INCOME</th>\n      <th>PARENT1</th>\n      <th>HOME_VAL</th>\n      <th>...</th>\n      <th>BLUEBOOK</th>\n      <th>TIF</th>\n      <th>CAR_TYPE</th>\n      <th>RED_CAR</th>\n      <th>OLDCLAIM</th>\n      <th>CLM_FREQ</th>\n      <th>REVOKED</th>\n      <th>MVR_PTS</th>\n      <th>CAR_AGE</th>\n      <th>URBANICITY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>60.0</td>\n      <td>0</td>\n      <td>11.0</td>\n      <td>67349.0</td>\n      <td>No</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>14230</td>\n      <td>11</td>\n      <td>Minivan</td>\n      <td>yes</td>\n      <td>4461</td>\n      <td>2</td>\n      <td>No</td>\n      <td>3</td>\n      <td>18.0</td>\n      <td>Highly Urban/ Urban</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>43.0</td>\n      <td>0</td>\n      <td>11.0</td>\n      <td>91449.0</td>\n      <td>No</td>\n      <td>257252.0</td>\n      <td>...</td>\n      <td>14940</td>\n      <td>1</td>\n      <td>Minivan</td>\n      <td>yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>Highly Urban/ Urban</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>10.0</td>\n      <td>16039.0</td>\n      <td>No</td>\n      <td>124191.0</td>\n      <td>...</td>\n      <td>4010</td>\n      <td>4</td>\n      <td>z_SUV</td>\n      <td>no</td>\n      <td>38690</td>\n      <td>2</td>\n      <td>No</td>\n      <td>3</td>\n      <td>10.0</td>\n      <td>Highly Urban/ Urban</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>51.0</td>\n      <td>0</td>\n      <td>14.0</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>306251.0</td>\n      <td>...</td>\n      <td>15440</td>\n      <td>7</td>\n      <td>Minivan</td>\n      <td>yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>Highly Urban/ Urban</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>50.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>114986.0</td>\n      <td>No</td>\n      <td>243925.0</td>\n      <td>...</td>\n      <td>18000</td>\n      <td>1</td>\n      <td>z_SUV</td>\n      <td>no</td>\n      <td>19217</td>\n      <td>2</td>\n      <td>Yes</td>\n      <td>3</td>\n      <td>17.0</td>\n      <td>Highly Urban/ Urban</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 166
    }
   ],
   "source": [
    "#This is how our training set looks like\n",
    "\n",
    "training_set.head() # printing the head of the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   INDEX  TARGET_FLAG  TARGET_AMT  KIDSDRIV   AGE  HOMEKIDS   YOJ   INCOME  \\\n",
       "0      3          NaN  161.101900         0  48.0         0  11.0  52881.0   \n",
       "1      9          NaN  253.867641         1  40.0         1  11.0  50815.0   \n",
       "2     10          NaN  145.172185         0  44.0         2  12.0  43486.0   \n",
       "3     18          NaN  148.925450         0  35.0         2   NaN  21204.0   \n",
       "4     21          NaN  263.740847         0  59.0         0  12.0  87460.0   \n",
       "\n",
       "  PARENT1  HOME_VAL  ... BLUEBOOK TIF CAR_TYPE RED_CAR  OLDCLAIM CLM_FREQ  \\\n",
       "0      No       0.0  ...    21970   1      Van     yes         0        0   \n",
       "1     Yes       0.0  ...    18930   6  Minivan      no      3295        1   \n",
       "2     Yes       0.0  ...     5900  10    z_SUV      no         0        0   \n",
       "3     Yes       0.0  ...     9230   6   Pickup      no         0        0   \n",
       "4      No       0.0  ...    15420   1  Minivan     yes     44857        2   \n",
       "\n",
       "   REVOKED  MVR_PTS CAR_AGE             URBANICITY  \n",
       "0       No        2    10.0    Highly Urban/ Urban  \n",
       "1       No        2     1.0    Highly Urban/ Urban  \n",
       "2       No        0    10.0  z_Highly Rural/ Rural  \n",
       "3      Yes        0     4.0  z_Highly Rural/ Rural  \n",
       "4       No        4     1.0    Highly Urban/ Urban  \n",
       "\n",
       "[5 rows x 26 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>INDEX</th>\n      <th>TARGET_FLAG</th>\n      <th>TARGET_AMT</th>\n      <th>KIDSDRIV</th>\n      <th>AGE</th>\n      <th>HOMEKIDS</th>\n      <th>YOJ</th>\n      <th>INCOME</th>\n      <th>PARENT1</th>\n      <th>HOME_VAL</th>\n      <th>...</th>\n      <th>BLUEBOOK</th>\n      <th>TIF</th>\n      <th>CAR_TYPE</th>\n      <th>RED_CAR</th>\n      <th>OLDCLAIM</th>\n      <th>CLM_FREQ</th>\n      <th>REVOKED</th>\n      <th>MVR_PTS</th>\n      <th>CAR_AGE</th>\n      <th>URBANICITY</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>161.101900</td>\n      <td>0</td>\n      <td>48.0</td>\n      <td>0</td>\n      <td>11.0</td>\n      <td>52881.0</td>\n      <td>No</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>21970</td>\n      <td>1</td>\n      <td>Van</td>\n      <td>yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>2</td>\n      <td>10.0</td>\n      <td>Highly Urban/ Urban</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>253.867641</td>\n      <td>1</td>\n      <td>40.0</td>\n      <td>1</td>\n      <td>11.0</td>\n      <td>50815.0</td>\n      <td>Yes</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>18930</td>\n      <td>6</td>\n      <td>Minivan</td>\n      <td>no</td>\n      <td>3295</td>\n      <td>1</td>\n      <td>No</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>Highly Urban/ Urban</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10</td>\n      <td>NaN</td>\n      <td>145.172185</td>\n      <td>0</td>\n      <td>44.0</td>\n      <td>2</td>\n      <td>12.0</td>\n      <td>43486.0</td>\n      <td>Yes</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>5900</td>\n      <td>10</td>\n      <td>z_SUV</td>\n      <td>no</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No</td>\n      <td>0</td>\n      <td>10.0</td>\n      <td>z_Highly Rural/ Rural</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18</td>\n      <td>NaN</td>\n      <td>148.925450</td>\n      <td>0</td>\n      <td>35.0</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>21204.0</td>\n      <td>Yes</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>9230</td>\n      <td>6</td>\n      <td>Pickup</td>\n      <td>no</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>4.0</td>\n      <td>z_Highly Rural/ Rural</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>21</td>\n      <td>NaN</td>\n      <td>263.740847</td>\n      <td>0</td>\n      <td>59.0</td>\n      <td>0</td>\n      <td>12.0</td>\n      <td>87460.0</td>\n      <td>No</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>15420</td>\n      <td>1</td>\n      <td>Minivan</td>\n      <td>yes</td>\n      <td>44857</td>\n      <td>2</td>\n      <td>No</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>Highly Urban/ Urban</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 167
    }
   ],
   "source": [
    "#This is how our features in the training set looks like\n",
    "\n",
    "validation_set.head() # printing the head of the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              INDEX  TARGET_FLAG   TARGET_AMT     KIDSDRIV          AGE  \\\n",
       "count   2141.000000          0.0  2141.000000  2141.000000  2140.000000   \n",
       "mean    5150.098552          NaN   270.318591     0.162541    45.016822   \n",
       "std     2956.329272          NaN   214.629080     0.486949     8.525006   \n",
       "min        3.000000          NaN     3.165496     0.000000    17.000000   \n",
       "25%     2632.000000          NaN    81.813150     0.000000    39.000000   \n",
       "50%     5224.000000          NaN   225.875822     0.000000    45.000000   \n",
       "75%     7669.000000          NaN   405.884160     0.000000    51.000000   \n",
       "max    10300.000000          NaN   960.498458     3.000000    73.000000   \n",
       "\n",
       "          HOMEKIDS          YOJ         INCOME       HOME_VAL     TRAVTIME  \\\n",
       "count  2141.000000  2047.000000    2016.000000    2030.000000  2141.000000   \n",
       "mean      0.717422    10.379091   60324.265377  153217.671429    33.152265   \n",
       "std       1.116579     4.170008   47003.422189  129456.870285    15.722393   \n",
       "min       0.000000     0.000000       0.000000       0.000000     5.000000   \n",
       "25%       0.000000     9.000000   25817.750000       0.000000    22.000000   \n",
       "50%       0.000000    11.000000   51778.000000  158840.000000    33.000000   \n",
       "75%       1.000000    13.000000   86278.250000  236651.500000    43.000000   \n",
       "max       5.000000    19.000000  291182.000000  669271.000000   105.000000   \n",
       "\n",
       "           BLUEBOOK          TIF      OLDCLAIM     CLM_FREQ      MVR_PTS  \\\n",
       "count   2141.000000  2141.000000   2141.000000  2141.000000  2141.000000   \n",
       "mean   15469.425502     5.244745   4022.167679     0.808968     1.765997   \n",
       "std     8462.367121     3.971026   8565.379145     1.137481     2.203413   \n",
       "min     1500.000000     1.000000      0.000000     0.000000     0.000000   \n",
       "25%     8870.000000     1.000000      0.000000     0.000000     0.000000   \n",
       "50%    14170.000000     4.000000      0.000000     0.000000     1.000000   \n",
       "75%    21050.000000     7.000000   4718.000000     2.000000     3.000000   \n",
       "max    49940.000000    25.000000  54399.000000     5.000000    12.000000   \n",
       "\n",
       "           CAR_AGE  \n",
       "count  2012.000000  \n",
       "mean      8.183400  \n",
       "std       5.766263  \n",
       "min       0.000000  \n",
       "25%       1.000000  \n",
       "50%       8.000000  \n",
       "75%      12.000000  \n",
       "max      26.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>INDEX</th>\n      <th>TARGET_FLAG</th>\n      <th>TARGET_AMT</th>\n      <th>KIDSDRIV</th>\n      <th>AGE</th>\n      <th>HOMEKIDS</th>\n      <th>YOJ</th>\n      <th>INCOME</th>\n      <th>HOME_VAL</th>\n      <th>TRAVTIME</th>\n      <th>BLUEBOOK</th>\n      <th>TIF</th>\n      <th>OLDCLAIM</th>\n      <th>CLM_FREQ</th>\n      <th>MVR_PTS</th>\n      <th>CAR_AGE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2141.000000</td>\n      <td>0.0</td>\n      <td>2141.000000</td>\n      <td>2141.000000</td>\n      <td>2140.000000</td>\n      <td>2141.000000</td>\n      <td>2047.000000</td>\n      <td>2016.000000</td>\n      <td>2030.000000</td>\n      <td>2141.000000</td>\n      <td>2141.000000</td>\n      <td>2141.000000</td>\n      <td>2141.000000</td>\n      <td>2141.000000</td>\n      <td>2141.000000</td>\n      <td>2012.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5150.098552</td>\n      <td>NaN</td>\n      <td>270.318591</td>\n      <td>0.162541</td>\n      <td>45.016822</td>\n      <td>0.717422</td>\n      <td>10.379091</td>\n      <td>60324.265377</td>\n      <td>153217.671429</td>\n      <td>33.152265</td>\n      <td>15469.425502</td>\n      <td>5.244745</td>\n      <td>4022.167679</td>\n      <td>0.808968</td>\n      <td>1.765997</td>\n      <td>8.183400</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2956.329272</td>\n      <td>NaN</td>\n      <td>214.629080</td>\n      <td>0.486949</td>\n      <td>8.525006</td>\n      <td>1.116579</td>\n      <td>4.170008</td>\n      <td>47003.422189</td>\n      <td>129456.870285</td>\n      <td>15.722393</td>\n      <td>8462.367121</td>\n      <td>3.971026</td>\n      <td>8565.379145</td>\n      <td>1.137481</td>\n      <td>2.203413</td>\n      <td>5.766263</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>3.165496</td>\n      <td>0.000000</td>\n      <td>17.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>1500.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2632.000000</td>\n      <td>NaN</td>\n      <td>81.813150</td>\n      <td>0.000000</td>\n      <td>39.000000</td>\n      <td>0.000000</td>\n      <td>9.000000</td>\n      <td>25817.750000</td>\n      <td>0.000000</td>\n      <td>22.000000</td>\n      <td>8870.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5224.000000</td>\n      <td>NaN</td>\n      <td>225.875822</td>\n      <td>0.000000</td>\n      <td>45.000000</td>\n      <td>0.000000</td>\n      <td>11.000000</td>\n      <td>51778.000000</td>\n      <td>158840.000000</td>\n      <td>33.000000</td>\n      <td>14170.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>8.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7669.000000</td>\n      <td>NaN</td>\n      <td>405.884160</td>\n      <td>0.000000</td>\n      <td>51.000000</td>\n      <td>1.000000</td>\n      <td>13.000000</td>\n      <td>86278.250000</td>\n      <td>236651.500000</td>\n      <td>43.000000</td>\n      <td>21050.000000</td>\n      <td>7.000000</td>\n      <td>4718.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10300.000000</td>\n      <td>NaN</td>\n      <td>960.498458</td>\n      <td>3.000000</td>\n      <td>73.000000</td>\n      <td>5.000000</td>\n      <td>19.000000</td>\n      <td>291182.000000</td>\n      <td>669271.000000</td>\n      <td>105.000000</td>\n      <td>49940.000000</td>\n      <td>25.000000</td>\n      <td>54399.000000</td>\n      <td>5.000000</td>\n      <td>12.000000</td>\n      <td>26.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "source": [
    "validation_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: TARGET_FLAG, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "#This is how our target training set looks like\n",
    "\n",
    "training_target.head() # printing the head of the set"
   ]
  },
  {
   "source": [
    "## First dummy classifier : \n",
    "\n",
    "Now It is time to make the dummy classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 0 0 ... 0 0 0]\n0.747091243110839\n"
     ]
    }
   ],
   "source": [
    "Dummy = DummyClassifier(strategy=\"most_frequent\") # We predict the most frequence class that is in our data set \n",
    "\n",
    "Dummy.fit(X_train, y_train)\n",
    "dummy_pred = Dummy.predict(X_test)\n",
    "\n",
    "print(dummy_pred) #a vector of 0\n",
    "\n",
    "print(accuracy_score(y_test, dummy_pred)) # the percentage of well classified predicted target, in our y_test we have 73 % de 0"
   ]
  },
  {
   "source": [
    "### Data exploration : \n",
    "\n",
    "The exploration is : \n",
    "\n",
    "- Print the missing values \n",
    "- Have a quick look at the data features\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We have a lot of missing values to take into account in our transformation : "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              INDEX     TARGET_AMT     KIDSDRIV          AGE     HOMEKIDS  \\\n",
       "count   8161.000000    8161.000000  8161.000000  8155.000000  8161.000000   \n",
       "mean    5151.867663    1504.324648     0.171057    44.790313     0.721235   \n",
       "std     2978.893962    4704.026930     0.511534     8.627589     1.116323   \n",
       "min        1.000000       0.000000     0.000000    16.000000     0.000000   \n",
       "25%     2559.000000       0.000000     0.000000    39.000000     0.000000   \n",
       "50%     5133.000000       0.000000     0.000000    45.000000     0.000000   \n",
       "75%     7745.000000    1036.000000     0.000000    51.000000     1.000000   \n",
       "max    10302.000000  107586.136160     4.000000    81.000000     5.000000   \n",
       "\n",
       "               YOJ         INCOME       HOME_VAL     TRAVTIME      BLUEBOOK  \\\n",
       "count  7707.000000    7716.000000    7697.000000  8161.000000   8161.000000   \n",
       "mean     10.499286   61898.094609  154867.289723    33.485725  15709.899522   \n",
       "std       4.092474   47572.682808  129123.774574    15.908333   8419.734075   \n",
       "min       0.000000       0.000000       0.000000     5.000000   1500.000000   \n",
       "25%       9.000000   28097.000000       0.000000    22.000000   9280.000000   \n",
       "50%      11.000000   54028.000000  161160.000000    33.000000  14440.000000   \n",
       "75%      13.000000   85986.000000  238724.000000    44.000000  20850.000000   \n",
       "max      23.000000  367030.000000  885282.000000   142.000000  69740.000000   \n",
       "\n",
       "               TIF      OLDCLAIM     CLM_FREQ      MVR_PTS      CAR_AGE  \n",
       "count  8161.000000   8161.000000  8161.000000  8161.000000  7651.000000  \n",
       "mean      5.351305   4037.076216     0.798554     1.695503     8.328323  \n",
       "std       4.146635   8777.139104     1.158453     2.147112     5.700742  \n",
       "min       1.000000      0.000000     0.000000     0.000000    -3.000000  \n",
       "25%       1.000000      0.000000     0.000000     0.000000     1.000000  \n",
       "50%       4.000000      0.000000     0.000000     1.000000     8.000000  \n",
       "75%       7.000000   4636.000000     2.000000     3.000000    12.000000  \n",
       "max      25.000000  57037.000000     5.000000    13.000000    28.000000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>INDEX</th>\n      <th>TARGET_AMT</th>\n      <th>KIDSDRIV</th>\n      <th>AGE</th>\n      <th>HOMEKIDS</th>\n      <th>YOJ</th>\n      <th>INCOME</th>\n      <th>HOME_VAL</th>\n      <th>TRAVTIME</th>\n      <th>BLUEBOOK</th>\n      <th>TIF</th>\n      <th>OLDCLAIM</th>\n      <th>CLM_FREQ</th>\n      <th>MVR_PTS</th>\n      <th>CAR_AGE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8161.000000</td>\n      <td>8161.000000</td>\n      <td>8161.000000</td>\n      <td>8155.000000</td>\n      <td>8161.000000</td>\n      <td>7707.000000</td>\n      <td>7716.000000</td>\n      <td>7697.000000</td>\n      <td>8161.000000</td>\n      <td>8161.000000</td>\n      <td>8161.000000</td>\n      <td>8161.000000</td>\n      <td>8161.000000</td>\n      <td>8161.000000</td>\n      <td>7651.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5151.867663</td>\n      <td>1504.324648</td>\n      <td>0.171057</td>\n      <td>44.790313</td>\n      <td>0.721235</td>\n      <td>10.499286</td>\n      <td>61898.094609</td>\n      <td>154867.289723</td>\n      <td>33.485725</td>\n      <td>15709.899522</td>\n      <td>5.351305</td>\n      <td>4037.076216</td>\n      <td>0.798554</td>\n      <td>1.695503</td>\n      <td>8.328323</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2978.893962</td>\n      <td>4704.026930</td>\n      <td>0.511534</td>\n      <td>8.627589</td>\n      <td>1.116323</td>\n      <td>4.092474</td>\n      <td>47572.682808</td>\n      <td>129123.774574</td>\n      <td>15.908333</td>\n      <td>8419.734075</td>\n      <td>4.146635</td>\n      <td>8777.139104</td>\n      <td>1.158453</td>\n      <td>2.147112</td>\n      <td>5.700742</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>16.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>1500.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-3.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2559.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>39.000000</td>\n      <td>0.000000</td>\n      <td>9.000000</td>\n      <td>28097.000000</td>\n      <td>0.000000</td>\n      <td>22.000000</td>\n      <td>9280.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5133.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>45.000000</td>\n      <td>0.000000</td>\n      <td>11.000000</td>\n      <td>54028.000000</td>\n      <td>161160.000000</td>\n      <td>33.000000</td>\n      <td>14440.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>8.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7745.000000</td>\n      <td>1036.000000</td>\n      <td>0.000000</td>\n      <td>51.000000</td>\n      <td>1.000000</td>\n      <td>13.000000</td>\n      <td>85986.000000</td>\n      <td>238724.000000</td>\n      <td>44.000000</td>\n      <td>20850.000000</td>\n      <td>7.000000</td>\n      <td>4636.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10302.000000</td>\n      <td>107586.136160</td>\n      <td>4.000000</td>\n      <td>81.000000</td>\n      <td>5.000000</td>\n      <td>23.000000</td>\n      <td>367030.000000</td>\n      <td>885282.000000</td>\n      <td>142.000000</td>\n      <td>69740.000000</td>\n      <td>25.000000</td>\n      <td>57037.000000</td>\n      <td>5.000000</td>\n      <td>13.000000</td>\n      <td>28.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "training_features.describe()"
   ]
  },
  {
   "source": [
    "We can also observ that the data are not scaled at all. A rescaling for the numerical could be done. There are huge outliners in some features like \"TRAVTIME\" or \"CAR_AGE\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Data treatment : \n",
    "\n",
    "I will then be able : \n",
    "- to complete the mising values if there are\n",
    "- properly encode the non numeric data to take them into account in my model.\n",
    "- rescale the data if needed, it depends on the values and in the model that I apply"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we separate for he treatments the features\n",
    "numerical_features = make_column_selector(dtype_include = np.number)\n",
    "categorical_features = make_column_selector(dtype_exclude = np.number)\n",
    "\n",
    "\n",
    "#Then we make our pipeline with our tranformations\n",
    "numerical_pipeline = make_pipeline(SimpleImputer(strategy='median'), RobustScaler()) \n",
    "categorical_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder())\n",
    "preprocessor = make_column_transformer((numerical_pipeline, numerical_features), (categorical_pipeline, categorical_features))"
   ]
  },
  {
   "source": [
    "## Machine Learning Model :\n",
    "I will implement a XGBoostClassifier and finetuned its hyperparameters thanks to a Cross vaidation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done 113 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 189 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=-1)]: Done 210 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 233 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:   38.0s\n",
      "[Parallel(n_jobs=-1)]: Done 281 tasks      | elapsed:   41.3s\n",
      "[Parallel(n_jobs=-1)]: Done 306 tasks      | elapsed:   43.6s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   46.6s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:   49.3s\n",
      "[Parallel(n_jobs=-1)]: Done 389 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   56.9s\n",
      "[Parallel(n_jobs=-1)]: Done 449 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 513 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 546 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 581 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 653 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 690 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 729 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 809 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 850 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 893 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 936 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1026 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1073 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1169 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1218 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1269 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1320 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1373 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1481 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1536 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1593 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1650 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1709 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1768 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1829 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1890 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1953 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2025 out of 2025 | elapsed:  4.5min finished\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier() # Defining my classifier\n",
    "\n",
    "#Defining the params to be tuned\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "#The grid search \n",
    "gd_sr = GridSearchCV(estimator=clf,\n",
    "                     param_grid=params,\n",
    "                     scoring='accuracy',\n",
    "                     cv=5,\n",
    "                     n_jobs=-1,\n",
    "                     verbose=10)\n",
    "#The final pipeline\n",
    "model = make_pipeline(preprocessor, gd_sr)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "source": [
    "At the end, my model has an accuracy of 1 over the test set "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#  accuracy is very good since it is one, so 100 % of our testing set is well predicted :\n",
    "\n",
    "print(accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(validation_features)"
   ]
  },
  {
   "source": [
    "## Deeplearning Model: \n",
    "\n",
    "I don't have more time to implement a Deeplearning model (because I had to do this in 2 hours). Yet we could implement a multiLayre perceptron with pytorch or Keras."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}